# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W1WpWfgn2Sjkik1aS7-Xa0QQCq7RyBrT

Reference: https://github.com/tobran/DF-GAN
"""

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/My Drive/IIITD/Courses/Sem 8/Deep Learning (CSE641)/Project/Deep Learning/Project/DF_GAN/code

from __future__ import print_function

from miscc.utils import mkdir_p
from miscc.config import cfg, cfg_from_file, _merge_a_into_b
from datasets import TextDataset
from datasets import prepare_data
from DAMSM import RNN_ENCODER

import os
import sys
import time
import random
import pprint
import datetime
import dateutil.tz
import argparse
import numpy as np
from PIL import Image
from easydict import EasyDict as edict

import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
import torch.backends.cudnn as cudnn
import torchvision.transforms as transforms
from model import NetG, NetD
import torchvision.utils as vutils
# dir_path = (os.path.abspath(os.path.join(os.path.realpath(__file__), './.')))
dir_path = (os.path.abspath(os.path.join('./main.py', './.')))
sys.path.append(dir_path)

import multiprocessing
multiprocessing.set_start_method('spawn', True)
UPDATE_INTERVAL = 200

__C = edict()
cfg = __C

# Dataset name: flowers, birds
__C.DATASET_NAME = 'birds'
__C.CONFIG_NAME = ''
__C.DATA_DIR = ''
__C.GPU_ID = 0
__C.CUDA = True
__C.WORKERS = 6

__C.RNN_TYPE = 'LSTM'   # 'GRU'
__C.B_VALIDATION = False
__C.loss = 'hinge'
__C.TREE = edict()
__C.TREE.BRANCH_NUM = 3
__C.TREE.BASE_SIZE = 64


# Training options
__C.TRAIN = edict()
__C.TRAIN.BATCH_SIZE = 64
__C.TRAIN.MAX_EPOCH = 600
__C.TRAIN.SNAPSHOT_INTERVAL = 2000
__C.TRAIN.DISCRIMINATOR_LR = 2e-4
__C.TRAIN.GENERATOR_LR = 2e-4
__C.TRAIN.ENCODER_LR = 2e-4
__C.TRAIN.RNN_GRAD_CLIP = 0.25
__C.TRAIN.FLAG = True
__C.TRAIN.NET_E = ''
__C.TRAIN.NET_G = ''
__C.TRAIN.B_NET_D = True
__C.TRAIN.NF = 32
__C.TRAIN.SMOOTH = edict()
__C.TRAIN.SMOOTH.GAMMA1 = 5.0
__C.TRAIN.SMOOTH.GAMMA3 = 10.0
__C.TRAIN.SMOOTH.GAMMA2 = 5.0
__C.TRAIN.SMOOTH.LAMBDA = 1.0


# Modal options
__C.GAN = edict()
__C.GAN.DF_DIM = 64
__C.GAN.GF_DIM = 128
__C.GAN.Z_DIM = 100
__C.GAN.CONDITION_DIM = 100
__C.GAN.R_NUM = 2
__C.GAN.B_ATTENTION = True
__C.GAN.B_DCGAN = True


__C.TEXT = edict()
__C.TEXT.CAPTIONS_PER_IMAGE = 10
__C.TEXT.EMBEDDING_DIM = 256
__C.TEXT.WORDS_NUM = 18
__C.TEXT.DAMSM_NAME = '../DAMSMencoders/coco/text_encoder200.pth'

# PARAMETERS
args = {
    'gpu_id': 0,
    'data_dir': '',
    'manualSeed': None
}

cfg2 = edict({
    'CONFIG_NAME': 'bird',
    'DATASET_NAME': 'birds',
    'DATA_DIR': '../data/birds',
    'GPU_ID': 0,
    'WORKERS': 1,
    'B_VALIDATION': False,
    'loss': 'hinge',
    'TREE': {
        'BRANCH_NUM': 1,
        'BASE_SIZE': 256
    },
    'TRAIN': {
        'NF': 32,            # default 64
        'BATCH_SIZE': 20,
        'MAX_EPOCH': 100,
        'NET_G': '../test'
    },
    'TEXT': {
        'EMBEDDING_DIM': 256,
        'CAPTIONS_PER_IMAGE': 10,
        'DAMSM_NAME': '../DAMSMencoders/bird/inception/text_encoder200.pth'
    }
})

_merge_a_into_b(cfg2, cfg)

# Commented out IPython magic to ensure Python compatibility.
def sampling(text_encoder, netG, dataloader, device):
    
    model_dir = cfg.TRAIN.NET_G
    split_dir = 'valid'
    # Build and load the generator
    model_no = (len([file_name for file_name in os.listdir('models/%s/' % cfg.CONFIG_NAME)]) - 1 )//2
    print("%d models stored in the directory. Reading the latest one." %model_no)
    # netG.load_state_dict(torch.load('models/%s/netG_600.pth' % cfg.CONFIG_NAME))
    netG.load_state_dict(torch.load('models/%s/netG_%03d.pth' % (cfg.CONFIG_NAME, model_no)))
    netG.eval()

    batch_size = cfg.TRAIN.BATCH_SIZE
    s_tmp = model_dir
    save_dir = '%s/%s' % (s_tmp, split_dir)
    mkdir_p(save_dir)
    cnt = 0
    for i in range(1):  # (cfg.TEXT.CAPTIONS_PER_IMAGE):
        for step, data in enumerate(dataloader, 0):
            imags, captions, cap_lens, class_ids, keys = prepare_data(data)
            cnt += batch_size
            if step % 100 == 0:
                print('step: ', step)
            hidden = text_encoder.init_hidden(batch_size)
            # words_embs: batch_size x nef x seq_len
            # sent_emb: batch_size x nef
            words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)
            words_embs, sent_emb = words_embs.detach(), sent_emb.detach()
            #######################################################
            # (2) Generate fake images
            ######################################################
            with torch.no_grad():
                noise = torch.randn(batch_size, 100)
                noise=noise.to(device)
                fake_imgs = netG(noise, sent_emb)
            for j in range(batch_size):
                s_tmp = '%s/single/%s' % (save_dir, keys[j])
                folder = s_tmp[:s_tmp.rfind('/')]
                if not os.path.isdir(folder):
                    print('%3d.%2d -> Make a new folder: %s' % (step, j+1, folder))
                    mkdir_p(folder)
                else:
                    print('%3d.%2d -> Saving in folder:  %s' % (step, j+1, folder))
                im = fake_imgs[j].data.cpu().numpy()
                
                im = (im + 1.0) * 127.5   # [-1, 1] -> [0, 255]
                im = im.astype(np.uint8)
                im = np.transpose(im, (1, 2, 0))
                im = Image.fromarray(im)
                fullpath = '%s_%3d.png' % (s_tmp, i)
                im.save(fullpath)


def train(dataloader, netG, netD, text_encoder, optimizerG, optimizerD, state_epoch, batch_size, device):
    for epoch in range(state_epoch+1, cfg.TRAIN.MAX_EPOCH+1):
        start = time.time()
        torch.cuda.empty_cache()
        for step, data in enumerate(dataloader, 0):
            
            imags, captions, cap_lens, class_ids, keys = prepare_data(data)
            hidden = text_encoder.init_hidden(batch_size)
            # words_embs: batch_size x nef x seq_len
            # sent_emb: batch_size x nef
            words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)
            words_embs, sent_emb = words_embs.detach(), sent_emb.detach()

            imgs = imags[0].to(device)
            real_features = netD(imgs)
            output = netD.COND_DNET(real_features, sent_emb)
            errD_real = torch.nn.ReLU()(1.0 - output).mean()

            output = netD.COND_DNET(real_features[:(batch_size - 1)], sent_emb[1:batch_size])
            errD_mismatch = torch.nn.ReLU()(1.0 + output).mean()

            # synthesize fake images
            noise = torch.randn(batch_size, 100)
            noise = noise.to(device)
            fake = netG(noise, sent_emb)
            
            # G does not need update with D
            fake_features = netD(fake.detach()) 

            errD_fake = netD.COND_DNET(fake_features, sent_emb)
            errD_fake = torch.nn.ReLU()(1.0 + errD_fake).mean()          

            errD = errD_real + (errD_fake + errD_mismatch)/2.0
            optimizerD.zero_grad()
            optimizerG.zero_grad()
            errD.backward()
            optimizerD.step()

            # MA-GP
            interpolated = imgs.data.requires_grad_()
            sent_inter = sent_emb.data.requires_grad_()
            features = netD(interpolated)
            out = netD.COND_DNET(features, sent_inter)
            grads = torch.autograd.grad(outputs=out,
                                        inputs=(interpolated,sent_inter),
                                        grad_outputs=torch.ones(out.size()).cuda(),
                                        retain_graph=True,
                                        create_graph=True,
                                        only_inputs=True)
            grad0 = grads[0].view(grads[0].size(0), -1)
            grad1 = grads[1].view(grads[1].size(0), -1)
            grad = torch.cat((grad0, grad1), dim=1)
            grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))
            d_loss_gp = torch.mean(grad_l2norm ** 6)
            d_loss = 2.0 * d_loss_gp
            optimizerD.zero_grad()
            optimizerG.zero_grad()
            d_loss.backward()
            optimizerD.step()
            
            # update G
            features = netD(fake)
            output = netD.COND_DNET(features, sent_emb)
            errG = - output.mean()
            optimizerG.zero_grad()
            optimizerD.zero_grad()
            errG.backward()
            optimizerG.step()

            print('[%d/%d][%d/%d] Loss_D: %.3f Loss_G %.3f'
#                 % (epoch, cfg.TRAIN.MAX_EPOCH, step+1, len(dataloader), errD.item(), errG.item()))

        vutils.save_image(fake.data,
                          '%s/fake_samples_epoch_%03d.png' % ('imgs/', epoch),
                          normalize=True)

        if epoch % 1 == 0:
            torch.save(netG.state_dict(), 'models/%s/netG_%03d.pth' % (cfg.CONFIG_NAME, epoch))
            torch.save(netD.state_dict(), 'models/%s/netD_%03d.pth' % (cfg.CONFIG_NAME, epoch))
        end = time.time()
        print("Time taken for %d: %d seconds or %.3f minutes" % (epoch, end-start, (end-start)/60))

if args['gpu_id'] == -1:
    cfg.CUDA = False
else:
    cfg.GPU_ID = args['gpu_id']

if args['data_dir'] != '':
    cfg.DATA_DIR = args['data_dir']
print('Using config:')
pprint.pprint(cfg)

if not cfg.TRAIN.FLAG:
    args['manualSeed '] = 100
elif args['manualSeed'] is None:
    args['manualSeed'] = 100
    # args['manualSeed'] = random.randint(1, 10000)
print("seed now is : ", args['manualSeed'])
random.seed(args['manualSeed'])
np.random.seed(args['manualSeed'])
torch.manual_seed(args['manualSeed'])
if cfg.CUDA:
    torch.cuda.manual_seed_all(args['manualSeed'])

now = datetime.datetime.now(dateutil.tz.tzlocal())
timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')
output_dir = '../output/%s_%s_%s' % \
    (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)

torch.cuda.set_device(cfg.GPU_ID)
cudnn.benchmark = True

# Get data loader ##################################################
imsize = cfg.TREE.BASE_SIZE
batch_size = cfg.TRAIN.BATCH_SIZE
image_transform = transforms.Compose([
    transforms.Resize(int(imsize * 76 / 64)),
    transforms.RandomCrop(imsize),
    transforms.RandomHorizontalFlip()])
if cfg.B_VALIDATION:
    dataset = TextDataset(cfg.DATA_DIR, 'test',
                            base_size=cfg.TREE.BASE_SIZE,
                            transform=image_transform)
    print(dataset.n_words, dataset.embeddings_num)
    assert dataset
    dataloader = torch.utils.data.DataLoader(
        dataset, batch_size=batch_size, drop_last=True,
        shuffle=True, num_workers=int(cfg.WORKERS))
else:     
    dataset = TextDataset(cfg.DATA_DIR, 'train',
                            base_size=cfg.TREE.BASE_SIZE,
                            transform=image_transform)
    print(dataset.n_words, dataset.embeddings_num)
    assert dataset
    dataloader = torch.utils.data.DataLoader(
        dataset, batch_size=batch_size, drop_last=True,
        shuffle=True, num_workers=int(cfg.WORKERS))

torch.cuda.is_available()

# For training
torch.cuda.empty_cache()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

netG = NetG(cfg.TRAIN.NF, 100).to(device)
netD = NetD(cfg.TRAIN.NF).to(device)

text_encoder = RNN_ENCODER(dataset.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)
state_dict = torch.load(cfg.TEXT.DAMSM_NAME, map_location=lambda storage, loc: storage)
text_encoder.load_state_dict(state_dict)
text_encoder.cuda()

for p in text_encoder.parameters():
    p.requires_grad = False
text_encoder.eval()    

state_epoch = 0

optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0001, betas=(0.0, 0.9))
optimizerD = torch.optim.Adam(netD.parameters(), lr=0.0004, betas=(0.0, 0.9))  

# if cfg.B_VALIDATION:
#     sampling(text_encoder, netG, dataloader, device)  # generate images for the whole valid dataset
#     print('state_epoch:  %d' % state_epoch)
# else:
cfg.B_VALIDATION = False
train(dataloader, netG, netD, text_encoder, optimizerG, optimizerD, state_epoch, batch_size, device)

# # validation data # #

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

netG = NetG(cfg.TRAIN.NF, 100).to(device)
netD = NetD(cfg.TRAIN.NF).to(device)

text_encoder = RNN_ENCODER(dataset.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)
state_dict = torch.load(cfg.TEXT.DAMSM_NAME, map_location=lambda storage, loc: storage)
text_encoder.load_state_dict(state_dict)
text_encoder.cuda()

for p in text_encoder.parameters():
    p.requires_grad = False
text_encoder.eval()    

state_epoch = 0

optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0001, betas=(0.0, 0.9))
optimizerD = torch.optim.Adam(netD.parameters(), lr=0.0004, betas=(0.0, 0.9))  

# if cfg.B_VALIDATION:
cfg.B_VALIDATION = True
start = time.time()
sampling(text_encoder, netG, dataloader, device)  # generate images for the whole valid dataset
# print('state_epoch:  %d' % state_epoch)
end = time.time()
print("Total time taken: %d seconds or %3f minutes." % (end-start, (end-start)/60))
# else:
    # train(dataloader, netG, netD, text_encoder, optimizerG, optimizerD, state_epoch, batch_size, device)