# -*- coding: utf-8 -*-
"""Copy of DC-GAN-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tphZt_dJhCYOIzMwGHB7cxHuiCHaer5Y
"""



from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/deep_learning/Deep\ Learning/Project/

cd DC_GAN/

# cd /content/drive/MyDrive/DL_project/DC_GAN

! pip install tensorboardX

ls

from IPython import display

from utils import Logger

import torch
from torch import nn
from torch.optim import Adam
from torch.autograd import Variable

from torchvision import transforms, datasets

import os
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader, TensorDataset 
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

torch.cuda.is_available()

train_data = np.load('./data_32/train_data.npy',allow_pickle=True)
train_attributes = np.load('./data_32/train_attributes.npy', allow_pickle=True)
train_emb_np = np.load('./data_32/train_data_embs.npy',allow_pickle=True)

test_data = np.load('./data_32/test_data.npy',allow_pickle=True)
test_attributes = np.load('./data_32/test_attributes.npy', allow_pickle=True)
test_emb_np = np.load('./data_32/test_data_embs.npy',allow_pickle=True)

print(train_data)
print(train_attributes)
print(train_emb_np)
# train_data_op = np.zeros((len(train_data),len(train_data[0]),len(train_data[0][0])))
# print(train_data_op.shape)

# for i in range(len(train_data_op)):
#     for j in range(len(train_data_op[0])):
#         for k in range(len(train_data_op[0][0])):
#             train_data_op[i][j][k] = train_data[i][j][k]
        
# test_data_op = np.zeros((len(test_data),len(test_data[0][0]),len(test_data[0][0][0])))
# print(test_data_op.shape)

# for i in range(len(test_data_op)):
#     for j in range(len(test_data_op[0])):
#         for k in range(len(test_data_op[0][0])):
#             test_data_op[i][j][k] = test_data[i][j][k]
        

train_attributes_oh = np.zeros(train_attributes.shape[0:2])
test_attributes_oh = np.zeros(test_attributes.shape[0:2])

for i in range(len(train_attributes)):
    for j in range(len(train_attributes[0])):
        train_attributes_oh[i][j] = train_attributes[i][j][0]

for i in range(len(test_attributes)):
    for j in range(len(test_attributes[0])):
        test_attributes_oh[i][j] = test_attributes[i][j][0]


train_attributes_ct = np.zeros((train_attributes.shape[0:2]))
test_attributes_ct = np.zeros((test_attributes.shape[0:2]))

for i in range(len(train_attributes)):
    for j in range(len(train_attributes[0])):
        train_attributes_ct[i][j] = train_attributes[i][j][1]

for i in range(len(test_attributes)):
    for j in range(len(test_attributes[0])):
        test_attributes_ct[i][j] = test_attributes[i][j][1]


train_emb = np.zeros((train_emb_np.shape[0:2]))
test_emb = np.zeros((test_emb_np.shape[0:2]))

for i in range(len(train_emb_np)):
  for j in range(len(train_emb_np[0])):
    train_emb[i][j] = train_emb_np[i][j]


for i in range(len(test_emb_np)):
  for j in range(len(test_emb_np[0])):
    test_emb[i][j] = test_emb_np[i][j]

train_attributes_oh = torch.from_numpy(train_attributes_oh)
test_attributes_oh = torch.from_numpy(test_attributes_oh)

train_attributes_ct = torch.from_numpy(train_attributes_ct)
test_attributes_ct = torch.from_numpy(test_attributes_ct)
# max_dif_train_emb = (np.max(train_emb)-np.min(train_emb))
# print(max_dif_train_emb)
# print(np.max(train_emb_np))
# print(train_emb_np)
# print(np.min(train_emb_np))
# train_emb = ((train_emb_np - np.min(train_emb_np))/(np.max(train_emb_np)-np.min(train_emb_np)))
# test_emb = ((test_emb_np - np.min(test_emb_np))/(np.max(test_emb_np)-np.min(test_emb_np)))

# print(train_emb)
# train_emb = torch.from_numpy(train_emb)
# test_emb = torch.from_numpy(test_emb)

train_emb = torch.from_numpy(train_emb_np)
test_emb = torch.from_numpy(test_emb_np)


# print(train_data)
# train_data = np.asarray(train_data, dtype = np.float32)
# test_data = np.asarray(test_data, dtype = np.float32)

# train_data_op = torch.from_numpy(train_data_op)
# test_data_op = torch.from_numpy(test_data_op)

# print(train_attributes_oh.shape)
# print(test_attributes_oh.shape)

print(type(train_attributes_oh))
print(type(train_attributes_oh[0]))

# print((train_attributes_oh.shape))
# print((train_attributes_oh[0].shape))

print((train_attributes_ct.shape))
print((train_attributes_ct[0].shape))

print("-----------------")

print(type(train_data))
print(type(train_data[0]))

print("-----------------")
print(train_emb.shape)
print(type(train_emb))
print(type(train_emb[0]))

def noise1(size):
    n = Variable(torch.randn(size, 100))
    # if torch.cuda.is_available(): return n.cuda()
    return n

def noise2(n):
    # n = Variable(torch.randn(size, 100))
    n = Variable(n)
    if torch.cuda.is_available(): return n.cuda()
    return n

def noise3(size):
    n = Variable(torch.randn(size, 200))
    if torch.cuda.is_available(): return n.cuda()
    return n

train_noise = noise1(len(train_data))
test_noise = noise1(len(train_data))

print(train_noise.shape)
print(type(train_noise))
print(type(train_noise[0]))

train_img_att = []
for i in range(len(train_data)):
    train_img_att.append([train_data[i],train_attributes_ct[i],train_emb[i],train_noise[i]])

test_img_att = []
for i in range(len(test_data)):
    test_img_att.append([test_data[i],test_attributes_ct[i],test_emb[i],test_noise[i]])

class CUBDataset2(Dataset):
    def __init__(self, data, labels,transform=None, target_transform=None):
        self.transform = transform
        self.target_transform = target_transform
        self.targets = labels
        self.data = data

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img, target = self.data[idx], self.targets[idx]

        if self.transform is not None:
            img = self.transform(img)

        if self.target_transform is not None:
            target = self.target_transform(target)

        return img, target

train_data_obj = CUBDataset2(train_img_att, np.load('./data_32/train_labels.npy', allow_pickle=True))
test_data_obj = CUBDataset2(test_img_att, np.load('./data_32/test_labels.npy', allow_pickle=True))

print(len(train_data_obj))

trainloader = torch.utils.data.DataLoader(train_data_obj, batch_size=64, shuffle=True, num_workers=2)
testloader = torch.utils.data.DataLoader(test_data_obj, batch_size=64, shuffle=True, num_workers=2)

print(len(trainloader))
num_batches = len(trainloader)

"""## Load Data"""

# def cifar_data():
#     compose = transforms.Compose(
#         [
#             transforms.Resize(64),
#             transforms.ToTensor(),
#             transforms.Normalize((.5, .5, .5), (.5, .5, .5))
#         ])
#     out_dir = '{}/dataset'.format(DATA_FOLDER)
#     return datasets.CIFAR10(root=out_dir, train=True, transform=compose, download=False)

# data = cifar_data()
# batch_size = 1000
# data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)
# num_batches = len(data_loader)

# print(num_batches)
# print(len(data_loader))
# print((data[0][0].shape))



"""## Networks"""

class DiscriminativeNet(torch.nn.Module):
    
    def __init__(self):
        super(DiscriminativeNet, self).__init__()
        
        self.conv1 = nn.Sequential(
            nn.Conv2d(
                in_channels=3, out_channels=128, kernel_size=4, 
                stride=2, padding=1, bias=False
            ),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(
                in_channels=128, out_channels=256, kernel_size=4,
                stride=2, padding=1, bias=False
            ),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.conv3 = nn.Sequential(
            nn.Conv2d(
                in_channels=256, out_channels=512, kernel_size=4,
                stride=2, padding=1, bias=False
            ),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.conv4 = nn.Sequential(
            nn.Conv2d(
                in_channels=512, out_channels=1024, kernel_size=4,
                stride=2, padding=1, bias=False
            ),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.out = nn.Sequential(
            nn.Linear(1024*4*4, 1),
            nn.Sigmoid(),
        )

    def forward(self, x):
        print("------------------DISCRIMINATOR - STARTS-----------------------")
        print(x.shape)
        # Convolutional layers
        x = self.conv1(x)
        print(x.shape)
        x = self.conv2(x)
        print(x.shape)
        x = self.conv3(x)
        print(x.shape)
        x = self.conv4(x)
        print(x.shape)
        # Flatten and apply sigmoid
        x = x.view(-1, 1024*4*4)
        print(x.shape)
        x = self.out(x)
        print(x.shape)
        print("------------------DISCRIMINATOR - CLOSED-----------------------")
        print()
        print()
        return x

class GenerativeNet(torch.nn.Module):
    
    def __init__(self):
        super(GenerativeNet, self).__init__()
        
        self.linear = torch.nn.Linear(100, 1024*4*4)
        
        self.conv1 = nn.Sequential(
            nn.ConvTranspose2d(
                in_channels=1024, out_channels=512, kernel_size=4,
                stride=2, padding=1, bias=False
            ),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True)
        )
        self.conv2 = nn.Sequential(
            nn.ConvTranspose2d(
                in_channels=512, out_channels=256, kernel_size=4,
                stride=2, padding=1, bias=False
            ),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True)
        )
        self.conv3 = nn.Sequential(
            nn.ConvTranspose2d(
                in_channels=256, out_channels=128, kernel_size=4,
                stride=2, padding=1, bias=False
            ),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True)
        )
        self.conv4 = nn.Sequential(
            nn.ConvTranspose2d(
                in_channels=128, out_channels=3, kernel_size=4,
                stride=2, padding=1, bias=False
            )
        )
        self.out = torch.nn.Tanh()

    def forward(self, x):
        print("------------------GENERATOR - STARTS-----------------------")
        # Project and reshape
        x = self.linear(x)
        print(x.shape)
        x = x.view(x.shape[0], 1024, 4, 4)
        # Convolutional layers
        print(x.shape)
        x = self.conv1(x)
        print(x.shape)
        x = self.conv2(x)
        print(x.shape)
        x = self.conv3(x)
        print(x.shape)
        x = self.conv4(x)
        print(x.shape)
        # Apply Tanh
        x = self.out(x)
        print(x.shape)
        print("------------------GENERATOR - CLOSED-----------------------")
        return x
    
# Noise
# def noise(n):
#     # n = Variable(torch.randn(size, 100))
#     if torch.cuda.is_available(): return n.cuda()
#     return n

"""#Copy Network for experiment purpose"""

class DiscriminativeNet(torch.nn.Module):
    
    def __init__(self):
        super(DiscriminativeNet, self).__init__()
        
        self.conv1 = nn.Sequential(
            nn.Conv2d(
                in_channels=3, out_channels=128, kernel_size=4, 
                stride=2, padding=1, bias=False
            ),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(
                in_channels=128, out_channels=256, kernel_size=4,
                stride=2, padding=1, bias=False
            ),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.conv3 = nn.Sequential(
            nn.Conv2d(
                in_channels=256, out_channels=512, kernel_size=4,
                stride=2, padding=1, bias=False
            ),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True)
        )
        # self.conv4 = nn.Sequential(
        #     nn.Conv2d(
        #         in_channels=512, out_channels=1024, kernel_size=4,
        #         stride=2, padding=1, bias=False
        #     ),
        #     nn.BatchNorm2d(1024),
        #     nn.LeakyReLU(0.2, inplace=True)
        # )
        # self.out = nn.Sequential(
        #     nn.Linear(1024*4*4, 1),
        #     nn.Sigmoid(),
        # )
        self.out = nn.Sequential(
            nn.Linear(512*4*4, 1),
            nn.Sigmoid(),
        )

    def forward(self, x):
        # print("------------------DISCRIMINATOR - STARTS-----------------------")
        # print(x.shape)
        # Convolutional layers
        x = self.conv1(x)
        # print(x.shape)
        x = self.conv2(x)
        # print(x.shape)
        x = self.conv3(x)
        # print(x.shape)
        # x = self.conv4(x)
        # print(x.shape)
        # Flatten and apply sigmoid
        # x = x.view(-1, 1024*4*4)
        x = x.view(-1, 512*4*4)
        # print(x.shape)
        x = self.out(x)
        # print(x.shape)
        # print("------------------DISCRIMINATOR - CLOSED-----------------------")
        # print()
        # print()
        return x

class GenerativeNet(torch.nn.Module):
    
    def __init__(self):
        super(GenerativeNet, self).__init__()
        
        # self.linear = torch.nn.Linear(100, 1024*4*4)
        self.linear_0 = torch.nn.Linear(768,100)  # for downsampling text data
        self.linear = torch.nn.Linear(200, 512*4*4)

        # self.conv1 = nn.Sequential(
        #     nn.ConvTranspose2d(
        #         in_channels=1024, out_channels=512, kernel_size=4,
        #         stride=2, padding=1, bias=False
        #     ),
        #     nn.BatchNorm2d(512),
        #     nn.ReLU(inplace=True)
        # )
        self.conv2 = nn.Sequential(
            nn.ConvTranspose2d(
                in_channels=512, out_channels=256, kernel_size=4,
                stride=2, padding=1, bias=False
            ),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True)
        )
        self.conv3 = nn.Sequential(
            nn.ConvTranspose2d(
                in_channels=256, out_channels=128, kernel_size=4,
                stride=2, padding=1, bias=False
            ),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True)
        )
        self.conv4 = nn.Sequential(
            nn.ConvTranspose2d(
                in_channels=128, out_channels=3, kernel_size=4,
                stride=2, padding=1, bias=False
            )
        )
        self.out = torch.nn.Tanh()

    def forward(self, x):
        # print("------------------GENERATOR - STARTS-----------------------")
        # Project and reshape
        # print(x.shape)
        # print(x.shape)
        # print(type(x))
        text_x = x[:, 100:]
        # print(text_x.shape)
        tf_text_x = self.linear_0(text_x)
        x = torch.cat((x[:, :100], tf_text_x),dim=1)
        x = self.linear(x)
        # print(x.shape)
        
        x = x.view(x.shape[0], 512, 4, 4)
        # x = x.view(x.shape[0], 1024, 4, 4)
        # Convolutional layers
        # print(x.shape)
        # x = self.conv1(x)
        # print(x.shape)
        x = self.conv2(x)
        # print(x.shape)
        x = self.conv3(x)
        # print(x.shape)
        x = self.conv4(x)
        # print(x.shape)
        # Apply Tanh
        x = self.out(x)
        # print(x.shape)
        # print("------------------GENERATOR - CLOSED-----------------------")
        return x
    
# Noise
# def noise(n):
#     # n = Variable(torch.randn(size, 100))
#     if torch.cuda.is_available(): return n.cuda()
#     return n

def init_weights(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1 or classname.find('BatchNorm') != -1:
        m.weight.data.normal_(0.00, 0.02)

# Create Network instances and init weights
generator = GenerativeNet()
generator.apply(init_weights)

discriminator = DiscriminativeNet()
discriminator.apply(init_weights)

# Enable cuda if available
if torch.cuda.is_available():
    generator.cuda()
    discriminator.cuda()

"""## Optimization"""

# Optimizers
d_optimizer = Adam(discriminator.parameters(), lr=0.001, betas=(0.5, 0.999))
g_optimizer = Adam(generator.parameters(), lr=0.001, betas=(0.5, 0.999))

# Loss function
loss = nn.BCELoss()  # use sigmoid

# Number of epochs
num_epochs = 50

"""## Training"""

def real_data_target(size):
    '''
    Tensor containing ones, with shape = size
    '''
    data = Variable(torch.ones(size, 1))
    if torch.cuda.is_available(): return data.cuda()
    return data

def fake_data_target(size):
    '''
    Tensor containing zeros, with shape = size
    '''
    data = Variable(torch.zeros(size, 1))
    if torch.cuda.is_available(): return data.cuda()
    return data

def train_discriminator(optimizer, real_data, fake_data):
    # Reset gradients
    optimizer.zero_grad()
    
    # 1.1 Train on Real Data
    prediction_real = discriminator(real_data)
    # Calculate error and backpropagate
    error_real = loss(prediction_real, real_data_target(real_data.size(0)))
    error_real.backward()

    # 1.2 Train on Fake Data
    prediction_fake = discriminator(fake_data)
    # Calculate error and backpropagate
    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))
    error_fake.backward()
    
    # 1.3 Update weights with gradients
    optimizer.step()
    
    # Return error
    return error_real + error_fake, prediction_real, prediction_fake

def train_generator(optimizer, fake_data):
    # 2. Train Generator
    # Reset gradients
    optimizer.zero_grad()
    # Sample noise and generate fake data
    prediction = discriminator(fake_data)
    # Calculate error and backpropagate
    error = loss(prediction, real_data_target(prediction.size(0)))
    error.backward()
    # Update weights with gradients
    optimizer.step()
    # Return error
    return error

# def noise2(size):
#     n = Variable(torch.randn(size, 100))
#     if torch.cuda.is_available(): return n.cuda()
#     return n

"""### Generate Samples for Testing"""

num_test_samples = 16
test_noise = noise3(num_test_samples)

# test_noise = []
# for _, (real_batch, __) in enumerate(trainloader):
#     test_noise = real_batch[1].detach().clone()

for n_btach, (real_batch,_) in enumerate(testloader):
  real_noise = real_batch[3][:16]
  real_emb = real_batch[2][:16]
  test_noise = torch.cat((real_noise, real_emb),dim = 1)
  print(_[:16])
  break

print(test_noise.shape)

"""### Start training"""

num_epochs = 75

logger = Logger(model_name='DCGAN_OWN_64_2', data_name='CUB')
# CUDA_LAUNCH_BLOCKING=1
for epoch in range(num_epochs):
    for n_batch, (real_batch,_) in enumerate(trainloader):


        
        real_image = (real_batch[0])
        real_attribute = (real_batch[1])
        real_emb = real_batch[2]
        real_noise = real_batch[3]

        new_noise = noise1(len(real_noise))

        # print(real_image.shape)
        # print(real_attribute.shape)
        # print(real_emb.shape)
        # print(real_noise.shape)
        # sample = real_attribute
        # sample = real_emb[:, 0: 300]

        sample = torch.cat((new_noise,real_emb), dim = 1)
        # print(sample.shape)
        
        # 1. Train Discriminator
        real_data = Variable(real_image)
        if torch.cuda.is_available(): real_data = real_data.cuda()
        # Generate fake data
        # fake_data = generator(noise3(real_attribute.size(0))).detach()  # only noise
        # print((real_attribute[0][0]))
        fake_data = generator(noise2(sample.float())).detach()   # for sample with data
        # Train D
        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer, 
                                                                real_data, fake_data)

        # 2. Train Generator
        # Generate fake data
        # fake_data = generator(noise(real_batch.size(0)))
        fake_data = generator(noise2(sample.float()))
        # fake_data = generator(noise(real_attribute.size(0)))#.detach()
        # Train G
        g_error = train_generator(g_optimizer, fake_data)
        # Log error
        logger.log(d_error, g_error, epoch, n_batch, num_batches)
        # test_noise2 = real_attribute.clone().detach()
        # Display Progress
        if (n_batch) % 12 == 0:
            display.clear_output(True)
            # Display Images
            # test_images = generator(noise(real_attribute.float())).detach()
            # test_images = test_images[:10].data.cpu()
            test_images = generator(noise2(test_noise.float())).data.cpu()
            # test_images = generator(test_noise).data.cpu()
            logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);
            # Display status Logs
            logger.display_status(
                epoch, num_epochs, n_batch, num_batches,
                d_error, g_error, d_pred_real, d_pred_fake
            )
        # Model Checkpoints
        logger.save_models(generator, discriminator, epoch)

